实时语音合成-通义千问提供低延迟、流式文本输入与流式音频输出能力，提供多种拟人音色，支持多语种/方言合成，可在同一音色下输出多语种，并能自适应调节语气，流畅处理复杂文本。

相比于语音合成-通义千问，实时语音合成-通义千问支持如下功能：

流式输入文本

可无缝对接大模型流式输出，边生成边合成，提升交互式语音应用的实时性。

双向通信

通过 WebSocket 协议实现文本流式输入与音频流式输出，避免多次建立连接的开销，大幅降低延迟。

支持的模型
推荐使用 Qwen3-TTS Realtime。

Qwen3-TTS Realtime 提供 17 种音色，支持多语种及方言合成，并允许自定义输出音频的格式、采样率、语速、音量、音高和码率。

Qwen-TTS Realtime 仅提供 7 种音色，支持的语种限于中文和英文，不支持自定义输出音频的格式、采样率、语速、音量、音高及码率。

中国大陆（北京）国际（新加坡）
Qwen3-TTS RealtimeQwen-TTS Realtime
模型名称

版本

单价

支持的语种

免费额度（注）

qwen3-tts-flash-realtime

当前能力等同 qwen3-tts-flash-realtime-2025-09-18
稳定版

1元/万字符

中文（普通话、北京、上海、四川、南京、陕西、闽南、天津、粤语）、英文、西班牙语、俄语、意大利语、法语、韩语、日语、德语、葡萄牙语

各2000字符

有效期：百炼开通后90天内

qwen3-tts-flash-realtime-2025-09-18

快照版

Qwen3-TTS 按输入的字符数计费，计算规则如下：

一个汉字 = 2个字符

一个英文字母、一个标点符号、一个空格 = 1个字符

访问方式
实时语音合成 - 通义千问 API 基于 WebSocket 协议。若使用 Java/Python，推荐通过 DashScope SDK 调用，可免去处理 WebSocket 细节；也可使用任意语言的 WebSocket 库进行连接：

调用地址

中国大陆（北京）：wss://dashscope.aliyuncs.com/api-ws/v1/realtime

国际（新加坡）：wss://dashscope-intl.aliyuncs.com/api-ws/v1/realtime

查询参数

查询参数为model，需指定为要访问的model名称，请参见支持的模型。

消息头

使用 Bearer Token 鉴权：Authorization: Bearer DASHSCOPE_API_KEY

DASHSCOPE_API_KEY 是您在阿里云百炼上申请的API-KEY。
通过以下代码与 Qwen-TTS Realtime API 建立 WebSocket 连接。

建立WebSocket连接

 
# pip install websocket-client
import json
import websocket
import os

# 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
# 若没有配置环境变量，请用百炼API Key将下行替换为：API_KEY="sk-xxx"
API_KEY=os.getenv("DASHSCOPE_API_KEY")
# 以下是北京地域url，如果使用新加坡地域的模型，需要将url替换为：wss://dashscope-intl.aliyuncs.com/api-ws/v1/realtime?model=qwen3-tts-flash-realtime
API_URL = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime?model=qwen3-tts-flash-realtime"

headers = [
    "Authorization: Bearer " + API_KEY
]

def on_open(ws):
    print(f"Connected to server: {API_URL}")
def on_message(ws, message):
    data = json.loads(message)
    print("Received event:", json.dumps(data, indent=2))
def on_error(ws, error):
    print("Error:", error)

ws = websocket.WebSocketApp(
    API_URL,
    header=headers,
    on_open=on_open,
    on_message=on_message,
    on_error=on_error
)

ws.run_forever()
连接后可以接收到以下回调信息：

 
{
    "event_id": "event_xxx",
    "type": "session.created",
    "session": {
        "object": "realtime.session",
        "mode": "server_commit",
        "model": "qwen3-tts-flash-realtime",
        "voice": "Cherry",
        "response_format": "pcm",
        "sample_rate": 24000,
        "id": "sess_xxx"
    }
}
快速开始
运行代码前，您需要获取并配置 API Key。

您的 Python 版本需要不低于 3.10。
通过以下步骤快速体验 Realtime API 实时合成音频的功能。

准备运行环境

根据您的操作系统安装 pyaudio。

macOSDebian/UbuntuCentOSWindows
 
pip install pyaudio
安装完成后，通过 pip 安装 websocket 相关的依赖：

 
pip install websocket-client==1.8.0 websockets
创建客户端

在本地新建 python 文件，命名为tts_realtime_client.py并复制以下代码到文件中：

tts_realtime_client.py

选择语音合成模式

Realtime API 支持以下两种模式：

server_commit 模式

客户端仅发送文本。服务端会智能判断文本分段方式与合成时机。适合低延迟且无需手动控制合成节奏的场景，例如 GPS 导航。

commit 模式

客户端先将文本添加至缓冲区，再主动触发服务端合成指定文本。适合需精细控制断句和停顿的场景，例如新闻播报。

server_commit 模式commit 模式
在tts_realtime_client.py的同级目录下新建另一个 python 文件，命名为server_commit.py，并将以下代码复制进文件中：

server_commit.py

运行server_commit.py，即可听到 Realtime API 实时生成的音频。

交互流程
server_commit 模式commit 模式
将session.update事件的session.mode 设为"server_commit"以启用该模式，服务端会智能处理文本分段和合成时机。

交互流程如下：

客户端发送session.update事件，服务端响应session.created与session.updated事件。

客户端发送 input_text_buffer.append 事件追加文本至服务端缓冲区。

服务端智能处理文本分段和合成时机，并返回response.created、response.output_item.added、response.content_part.added、response.audio.delta事件。

服务端响应完成后响应response.audio.done、response.content_part.done、response.output_item.done、response.done。

服务端响应session.finished来结束会话。

生命周期

客户端事件

服务器事件

会话初始化

session.update

会话配置
session.created

会话已创建
session.updated

会话配置已更新
用户文本输入

input_text_buffer.append

添加文本到服务端
input_text_buffer.commit

立即合成服务端缓存的文本
session.finish

通知服务端不再有文本输入
input_text_buffer.committed

服务端收到提交的文本
服务器音频输出

无

response.created

服务端开始生成响应
response.output_item.added

响应时有新的输出内容
response.content_part.added

新的输出内容添加到assistant message
response.audio.delta

模型增量生成的音频
response.content_part.done

Assistant mesasge 的文本或音频内容流式输出完成
response.output_item.done

Assistant mesasge 的整个输出项流式传输完成
response.audio.done

音频生成完成
response.done

响应完成
API参考
实时语音合成-通义千问API参考

支持的音色
不同模型支持的音色有所差异，使用时将请求参数voice设置为如下表格的voice参数列对应的值：

Qwen3-TTS RealtimeQwen-TTS Realtime
音色名

voice参数

音色效果

描述

支持的语种

芊悦

Cherry

阳光积极、亲切自然小姐姐。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

晨煦

Ethan

标准普通话，带部分北方口音。阳光、温暖、活力、朝气。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

不吃鱼

Nofish

不会翘舌音的设计师。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

詹妮弗

Jennifer

品牌级、电影质感般美语女声。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

甜茶

Ryan

节奏拉满，戏感炸裂，真实与张力共舞。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

卡捷琳娜

Katerina

御姐音色，韵律回味十足。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

墨讲师

Elias

既保持学科严谨性，又通过叙事技巧将复杂知识转化为可消化的认知模块。

中文、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

上海-阿珍

Jada

风风火火的沪上阿姐。

中文（上海话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

北京-晓东

Dylan

北京胡同里长大的少年。

中文（北京话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

四川-晴儿

Sunny

甜到你心里的川妹子。

中文（四川话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

南京-老李

Li

耐心的瑜伽老师

中文（南京话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

陕西-秦川

Marcus

面宽话短，心实声沉——老陕的味道。

中文（陕西话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

闽南-阿杰

Roy

诙谐直爽、市井活泼的台湾哥仔形象。

中文（闽南语）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

天津-李彼得

Peter

天津相声，专业捧人。

中文（天津话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

粤语-阿强

Rocky

幽默风趣的阿强，在线陪聊。

中文（粤语）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

粤语-阿清

Kiki

甜美的港妹闺蜜。

中文（粤语）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

四川-程川

Eric

一个跳脱市井的四川成都男子。

中文（四川话）、英语、法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语

